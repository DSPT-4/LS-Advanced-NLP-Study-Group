{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The links between the pages are expressed \\nAnd the page surfer moves the page according to this matrix.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "\n",
    "text = '''\n",
    "TextRank is based on PageRank algorithm that is used on Google Search Engine. Its base concept is \n",
    "\"The linked page is good, much more if it from many linked page\". The links between the pages are expressed \n",
    "by matrix (like Round-robin table). We can convert this matrix to transition probability matrix by dividing \n",
    "the sum of links in each page. And the page surfer moves the page according to this matrix.\n",
    "'''\n",
    "\n",
    "summarize(text, ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the political bands which have connected them with another, and to assume among the powers of the earth, the separate and equal station to which the Laws of Nature and of Nature's God entitle them, a decent respect to the opinions of mankind requires that they should declare the causes which impel them to the separation.\",\n",
       " 'He has refused for a long time, after such dissolutions, to cause others to be elected; whereby the Legislative powers, incapable of Annihilation, have returned to the People at large for their exercise; the State remaining in the mean time exposed to all the dangers of invasion from without, and convulsions within.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Declaration of Independence\n",
    "f = open(\"./data/declaration_of_independence.txt\", \"r\")\n",
    "declaration = f.read()\n",
    "\n",
    "# Summarize the document\n",
    "summarize(declaration, ratio=0.05).split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pages', 'search', 'surfer', 'probability', 'round', 'matrix', 'like', 'base']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "keywords(text, ratio=0.5, split=True, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 78),\n",
       " ('the', 76),\n",
       " ('to', 64),\n",
       " ('and', 55),\n",
       " ('our', 25),\n",
       " ('for', 20),\n",
       " ('their', 20),\n",
       " ('has', 20),\n",
       " ('in', 18),\n",
       " ('He', 18),\n",
       " ('a', 15),\n",
       " ('these', 13),\n",
       " ('by', 13),\n",
       " ('have', 11),\n",
       " ('them', 11),\n",
       " ('that', 10),\n",
       " ('all', 10),\n",
       " ('is', 10),\n",
       " ('which', 9),\n",
       " ('with', 9),\n",
       " ('be', 9),\n",
       " ('his', 9),\n",
       " ('For', 9),\n",
       " ('are', 8),\n",
       " ('on', 8),\n",
       " ('We', 7),\n",
       " ('Laws', 6),\n",
       " ('they', 6),\n",
       " ('from', 6),\n",
       " ('us', 6),\n",
       " ('it', 5),\n",
       " ('among', 5),\n",
       " ('such', 5),\n",
       " ('most', 5),\n",
       " ('an', 5),\n",
       " ('should', 4),\n",
       " ('as', 4),\n",
       " ('right', 4),\n",
       " ('been', 4),\n",
       " ('Assent', 4),\n",
       " ('large', 4),\n",
       " ('at', 4),\n",
       " ('time', 4),\n",
       " ('States', 3),\n",
       " ('powers', 3),\n",
       " ('them,', 3),\n",
       " ('hold', 3),\n",
       " ('People', 3),\n",
       " ('new', 3),\n",
       " ('its', 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(declaration.split()).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 0.18274612451912534),\n",
       " ('government', 0.1704268404672953),\n",
       " ('laws', 0.15023721944877813),\n",
       " ('large', 0.1394680839981137),\n",
       " ('establish', 0.13581001475788437),\n",
       " ('right', 0.12343159322740224),\n",
       " ('hither', 0.12121412023708288),\n",
       " ('power', 0.1148350292906247),\n",
       " ('times', 0.11449164313896629),\n",
       " ('peace', 0.11394267290295407),\n",
       " ('absolute', 0.11293090860696055),\n",
       " ('long', 0.10872930877644976),\n",
       " ('war', 0.10027328418022759),\n",
       " ('state', 0.10024546224147723),\n",
       " ('united', 0.0988677173113322),\n",
       " ('jurisdiction foreign', 0.09523350837414297),\n",
       " ('mankind', 0.09219102102538687),\n",
       " ('purpose', 0.09219102102538682),\n",
       " ('domestic', 0.09219102102538677),\n",
       " ('seas', 0.09219102102538668),\n",
       " ('political', 0.09219102102538666),\n",
       " ('firm', 0.09219102102538666),\n",
       " ('unusual', 0.09219102102538661),\n",
       " ('object', 0.0921910210253866),\n",
       " ('indian', 0.0921910210253866),\n",
       " ('ages', 0.09219102102538654),\n",
       " ('repeated', 0.0921910210253865),\n",
       " ('arms', 0.09219102102538644),\n",
       " ('equal', 0.09219102102538643),\n",
       " ('pursuing', 0.09219102102538643),\n",
       " ('hath', 0.0921910210253864),\n",
       " ('judge', 0.09219102102538636),\n",
       " ('legislate', 0.08630799004742344),\n",
       " ('perfidy scarcely', 0.08200747744233547),\n",
       " ('citizens taken', 0.08200747744233547),\n",
       " ('assembled', 0.08200747744233544),\n",
       " ('congress', 0.08200747744233543),\n",
       " ('public', 0.07767947141953874),\n",
       " ('people', 0.07767947141953871),\n",
       " ('rule', 0.07753610814132499)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(declaration, split=True, lemmatize=True, scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a ChatBot with ChatterBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [###                 ] 14%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "\n",
    "chatbot = ChatBot(\"First Chatbot\")\n",
    "\n",
    "conversation = [\n",
    "    \"Hello\",\n",
    "    \"Hi there!\",\n",
    "    \"How are you doing?\",\n",
    "    \"I'm doing great.\",\n",
    "    \"That is good to hear\",\n",
    "    \"Thank you.\",\n",
    "    \"You're welcome.\"\n",
    "]\n",
    "\n",
    "trainer = ListTrainer(chatbot)\n",
    "trainer.train(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you doing?\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.get_response(\"Hi!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [                    ] 1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "ChatBot: Hi there!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: What is your favorite sport?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite sport?\n",
      "ChatBot: My favorite subjects include robotics, computer science, and natural language processing.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Do you prefer text classification or topic modeling?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you prefer text classification or topic modeling?\n",
      "ChatBot: What can you eat\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Fish and eggs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish and eggs\n",
      "ChatBot: Complex is better than complicated.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye\n",
      "ChatBot: Bye\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "import os\n",
    "\n",
    "bot= ChatBot('Bot')\n",
    "trainer = ChatterBotCorpusTrainer(bot)\n",
    "\n",
    "corpus_path = 'C:/Users/bruno/Downloads/chatterbot-corpus-chatterbot_corpus-data/english/'\n",
    "    \n",
    "for file in os.listdir(corpus_path):\n",
    "    trainer.train(corpus_path + file)\n",
    "\n",
    "while True:\n",
    "    message = input('You:')\n",
    "    print(message)\n",
    "    if message.strip() == 'Bye':\n",
    "        print('ChatBot: Bye')\n",
    "        break\n",
    "    else:\n",
    "        reply = bot.get_response(message)\n",
    "        print('ChatBot:', reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
